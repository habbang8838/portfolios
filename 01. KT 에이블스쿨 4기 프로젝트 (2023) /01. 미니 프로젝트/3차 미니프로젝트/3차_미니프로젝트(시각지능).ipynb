{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **저시력자를 위한 원화 화폐 분류**\n",
        "---\n",
        "- 본 과제는 UltraLytics YOLO v5 모델 사용을 권장합니다.\n",
        "    - 본 파일의 목차는 UltraLytics YOLO v5에 맞게 작성되어 있습니다.\n",
        "    - 다른 모델을 찾아서 사용하셔도 좋습니다.\n",
        "    - 산출물이 잘 나오면 됩니다 : )\n",
        "---"
      ],
      "metadata": {
        "id": "XT7PRhnMf-kI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.미션\n",
        "---\n",
        "- **과제 수행 목표**\n",
        "    - 본 과제는 Object Detection 문제입니다.\n",
        "    - Object Detection 문제로 접근하기 위해 **데이터셋 전처리**를 하셔야 합니다.\n",
        "    - 데이터셋 : money_dataset.zip\n",
        "        1. 데이터셋은 압축 파일로 제공됩니다.\n",
        "        2. 압축 파일 안에는 화폐마다 폴더가 개별적으로 존재합니다.\n",
        "        3. 폴더 안에는 화폐 이미지와 화폐 정보가 담긴 json 파일이 있습니다.\n",
        "    - 여러분이 직접 촬영한 화폐 사진들을 탐지 과정에서 이용 해보세요.\n",
        "    - 이미지에 화폐 하나만 나오게 촬영하는 것은 지양해주세요.\n",
        "    - 다양한 방법으로 화폐를 촬영하고 결과를 확인해보세요.\n",
        "        - ex 1) 화폐의 모든 종류를 한 이미지에 나오게 촬영\n",
        "        - ex 2) 여러 화폐를 겹치게 하여 촬영\n",
        "---\n",
        "- **Key Point**\n",
        "    1. 모델에 맞는 폴더 구조 확인\n",
        "    2. 이미지 축소 비율에 맞춰 좌표값 변경\n",
        "        - 좌표를 이미지 리사이즈한 비율로 변경\n",
        "    3. 모델에 맞는 정보 추출/형식 변경\n",
        "        - json 파일에서 정보 추출 및 모델 형식에 맞게 변경\n",
        "    4. 화폐당 하나의 클래스로 변경\n",
        "        - 총 8개 클래스\n",
        "    5. 모델 선택 필요\n",
        "---"
      ],
      "metadata": {
        "id": "47D2vGDYdCOz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.환경설정"
      ],
      "metadata": {
        "id": "aZon1K-Ag9be"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (1) 구글 드라이브 연동, 데이터 다운로드\n",
        "---\n",
        "- 아래의 코드 셀을 반드시 실행시켜야 합니다.\n",
        "---"
      ],
      "metadata": {
        "id": "CMgnHN9ZBF05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "xCplyiojBFwh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0eb30cc-5a55-4a55-e75e-658248ed19eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sUNGwmDxAda",
        "outputId": "be7fa3ee-f67b-4e30-c815-77e5f4fe13c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.13.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2023.11.17)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (2) 데이터셋 불러오기\n",
        "---\n",
        "- **세부요구사항**\n",
        "    - 데이터셋 파일의 압축을 해제하세요.\n",
        "---\n",
        "- 예제 코드에서는 zipfile 모듈을 이용하였습니다.\n",
        "    - [zipfile document](https://docs.python.org/3/library/zipfile.html#zipfile-objects)\n",
        "    - 해당 모듈 이외에 자신이 잘 알고 있는 방법을 사용해도 됩니다.\n",
        "---"
      ],
      "metadata": {
        "id": "J8vjv0acBAV4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkSa5ejf8LMe"
      },
      "outputs": [],
      "source": [
        "import zipfile, gdown,os\n",
        "url =\"https://drive.google.com/file/d/1k1tXDK35s6BsMTPGWSl5GVGNoPfC898X/view?usp=drive_link\"\n",
        "file_name = \"money_dataset.zip\"\n",
        "output = \"/content/drive/MyDrive/project_0921/\" + file_name # 변경 가능\n",
        "if not os.path.exists(output):\n",
        "    gdown.download(url=url, output=output, quiet=False, fuzzy=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 압축 파일 경로 : 유저별로 상이할 수 있음\n",
        "money_data = zipfile.ZipFile(output)"
      ],
      "metadata": {
        "id": "N4cdpkRv86QQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 압축 해제\n",
        "money_data.extractall('Dataset')"
      ],
      "metadata": {
        "id": "TDAyDRLT9hZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.데이터 전처리"
      ],
      "metadata": {
        "id": "QyEd-WNIhoSc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (1) 폴더 구조 생성 및 파일 이동\n",
        "---\n",
        "- **세부요구사항**\n",
        "    -  모델에서 요구하는 폴더 구조를 만들어야 합니다.\n",
        "        - Hint : Image와 Label을 구분하는 폴더를 만들어 주세요\n",
        "---\n",
        "- 예제 코드에서는 glob, shutil 모듈을 이용하였습니다.\n",
        "    - [glob document](https://docs.python.org/3/library/glob.html) | [shutil document](https://docs.python.org/3/library/shutil.html)\n",
        "    - 해당 모듈 이외에 자신이 잘 알고 있는 방법을 사용해도 됩니다.\n",
        "---"
      ],
      "metadata": {
        "id": "P81d6utx-3LY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.폴더 구조 만들기\n",
        "!mkdir /content/Dataset/images;\n",
        "!mkdir /content/Dataset/images/train; mkdir /content/Dataset/images/val\n",
        "\n",
        "!mkdir /content/Dataset/labels;\n",
        "!mkdir /content/Dataset/labels/train; mkdir /content/Dataset/labels/val"
      ],
      "metadata": {
        "id": "YBqCJU5z_UI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "fXEmoFXO4c6v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aaec81c-438e-48a8-db19-c97b9ec66fe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob, shutil"
      ],
      "metadata": {
        "id": "UuchlNA_DftJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Dataset metadata 입력\n",
        "won_list = ['10', '50', '100', '500', '1000', '5000', '10000', '50000']\n",
        "data_path = '/content/Dataset/'"
      ],
      "metadata": {
        "id": "Q3lnYcLS_UOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "- 데이터를 Training set | Validation set으로 분할하세요.\n",
        "    - 예시 : Training과 Validation은 8:2로 분리\n",
        "- Hint : 이미지 데이터는 /images에, JSON 데이터는 /labels에 넣어주세요\n",
        "    - 예시 : /dataset/images/train, /dataset/labels/train\n",
        "    - 예제 코드에서는 glob, shutil 모듈을 이용하였습니다.\n",
        "    - [glob document](https://docs.python.org/3/library/glob.html) | [shutil document](https://docs.python.org/3/library/shutil.html)\n",
        "\n",
        "    ※ 해당 모듈 이외에 자신이 잘 알고 있는 방법을 사용해도 됩니다.\n",
        "    \n",
        "---"
      ],
      "metadata": {
        "id": "ihJgeqXJG1Ml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 데이터를 Training set | Validation set으로 분할하세요.\n",
        "images = glob.glob(data_path + '*/*.jpg')\n",
        "labels = glob.glob(data_path + '*/*.json')\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=2023)"
      ],
      "metadata": {
        "id": "1qfGCSqy_kL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"/\".join(x_train[0].split('/')[:-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sS5MxnF7xF9n",
        "outputId": "6862479e-d1dd-487a-a1db-46346fd2f1b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Dataset/10'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# x_train 복사\n",
        "target_folder_1 = '/content/Dataset/images/train'  # 대상 폴더 경로 (원하는 폴더 경로로 변경)\n",
        "target_folder_2 = '/content/Dataset/images/val'\n",
        "target_folder_3 = '/content/Dataset/labels/train'\n",
        "target_folder_4 = '/content/Dataset/labels/val'\n",
        "\n",
        "# 파일을 대상 폴더로 복사\n",
        "for file_name in x_train:\n",
        "    destination_path = os.path.join(target_folder_1, file_name.split('/')[-1])  # 대상 폴더로 복사할 경로\n",
        "    shutil.copyfile(file_name, destination_path)\n",
        "\n",
        "for file_name in x_val:\n",
        "    destination_path = os.path.join(target_folder_2,  file_name.split('/')[-1])  # 대상 폴더로 복사할 경로\n",
        "    shutil.copyfile(file_name, destination_path)\n",
        "\n",
        "for file_name in y_train:\n",
        "    destination_path = os.path.join(target_folder_3,  file_name.split('/')[-1])  # 대상 폴더로 복사할 경로\n",
        "    shutil.copyfile(file_name, destination_path)\n",
        "\n",
        "for file_name in y_val:\n",
        "    destination_path = os.path.join(target_folder_4,  file_name.split('/')[-1])  # 대상 폴더로 복사할 경로\n",
        "    shutil.copyfile(file_name, destination_path)"
      ],
      "metadata": {
        "id": "g8qtqOn6tDPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (2) json에서 정보 추출\n",
        "---\n",
        "- **세부요구사항**\n",
        "    - json 파일에서 필요한 정보를 추출하세요:\n",
        "        - 위치 정보 : x1, x2, y1, y2\n",
        "        - 박스 정보 : shape_type\n",
        "        - 클래스 정보 : labels\n",
        "    - 화폐당 하나의 클래스로 변경하세요.\n",
        "        - json 파일에는 화폐 클래스가 앞뒷면으로 구분되어 있습니다.\n",
        "        - 화폐의 앞뒷면 구분을 없애주세요.\n",
        "            - 예시 : 'ten_front', 'ten_back' -> 'ten'\n",
        "    - 화폐의 위치 정보를 YOLO 모델 형식에 맞게 변경 해주세요.\n",
        "        - 사용되는 이미지는 원본에서 1/5로 축소되어 있습니다.\n",
        "        - json 파일의 정보는 원본 기준 데이터이므로 위치 정보 추출을 할 때 x값과 y값을 1/5로 줄여주세요.\n",
        "    - 이렇게 변경된 정보를 YOLO label 형식에 맞게 txt파일로 저장 해 주세요.\n",
        "        - Hint : YOLO Labeling Format [label, x-center, y-center, width-norm, height-norm]\n",
        "---"
      ],
      "metadata": {
        "id": "II_hsJ6bKYGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json"
      ],
      "metadata": {
        "id": "MgUoCewjM-Jf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json_path = '/content/Dataset/labels/'\n",
        "temp_list = ['train', 'val']"
      ],
      "metadata": {
        "id": "gBD1Zv9BKaxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########################\n",
        "# 이 셀부터 코드 작성하세요\n",
        "# Json 파일에서 필요한 정보만 골라 txt로 바꾸는 작업임을 기억하세요!\n",
        "#######################\n",
        "x_centers = []\n",
        "y_centers = []\n",
        "classes = []\n",
        "widths = []\n",
        "heights = []\n",
        "file_names = []\n",
        "\n",
        "train_file_names = []\n",
        "val_file_names = []"
      ],
      "metadata": {
        "id": "Mzh2Y8doMEK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in temp_list:\n",
        "    if i == 'train':\n",
        "        train_file_names = glob.glob(json_path+i+'/*.json')\n",
        "    else:\n",
        "        val_file_names = glob.glob(json_path+i+'/*.json')"
      ],
      "metadata": {
        "id": "-tMH4MPXf1td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_file_names.sort()\n",
        "val_file_names.sort()"
      ],
      "metadata": {
        "id": "Yi3IkM6Of8kf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_file_names[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Qikaeidf-RJ",
        "outputId": "ef46a8ad-8bb9-448a-e022-69bd6132348e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/Dataset/labels/train/10000_B_DESK_0_1.json',\n",
              " '/content/Dataset/labels/train/10000_B_DESK_0_10.json',\n",
              " '/content/Dataset/labels/train/10000_B_DESK_0_100.json',\n",
              " '/content/Dataset/labels/train/10000_B_DESK_0_101.json',\n",
              " '/content/Dataset/labels/train/10000_B_DESK_0_102.json']"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_file_names[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbVRG0UtFVg5",
        "outputId": "4f6d4ead-8481-46f7-d8d2-c2ea3b669168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/Dataset/labels/val/10000_B_DESK_0_111.json',\n",
              " '/content/Dataset/labels/val/10000_B_DESK_0_121.json',\n",
              " '/content/Dataset/labels/val/10000_B_DESK_0_126.json',\n",
              " '/content/Dataset/labels/val/10000_B_DESK_0_131.json',\n",
              " '/content/Dataset/labels/val/10000_B_DESK_0_135.json']"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_file_names[0].split('.json')[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "OtqPN8S_gAZo",
        "outputId": "41fc3314-b886-4ffd-ce13-22b0b29aa885"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Dataset/labels/train/10000_B_DESK_0_1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_txt(file_name,label,min_xy,max_xy,image_width,image_height):\n",
        "    file_name = file_name.split('.json')[0]+'.txt'\n",
        "    label = label.split('_back')[0].split('_front')[0]\n",
        "    x_min,y_min = min_xy\n",
        "    x_max,y_max = max_xy\n",
        "\n",
        "    if label == 'Ten':\n",
        "        label = 0\n",
        "    elif label == 'Fifty':\n",
        "        label = 1\n",
        "    elif label == 'Hundred':\n",
        "        label = 2\n",
        "    elif label == 'Five_Hundred':\n",
        "        label = 3\n",
        "    elif label == 'Thousand':\n",
        "        label = 4\n",
        "    elif label == 'Five_Thousand':\n",
        "        label = 5\n",
        "    elif label == 'Ten_Thousand':\n",
        "        label = 6\n",
        "    elif label == 'Fifty_Thousand':\n",
        "        label = 7\n",
        "\n",
        "    width = x_max - x_min\n",
        "    height = y_max - y_min\n",
        "    width_norm = round(width / image_width,7)\n",
        "    height_norm = round(height / image_height,7)\n",
        "\n",
        "    center_x = round(((x_min + x_max) / 2) / image_width,7)\n",
        "    center_y = round(((y_min + y_max) / 2) / image_height,7)\n",
        "\n",
        "    x_centers.append(center_x)\n",
        "    y_centers.append(center_y)\n",
        "    classes.append(label)\n",
        "    widths.append(width_norm)\n",
        "    heights.append(height_norm)\n",
        "    file_names.append(file_name)"
      ],
      "metadata": {
        "id": "FgkLcrN1gJTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########################\n",
        "# 이 셀부터 코드 작성하세요\n",
        "# Json 파일에서 필요한 정보만 골라 txt로 바꾸는 작업임을 기억하세요!\n",
        "########################\n",
        "x_centers = []\n",
        "y_centers = []\n",
        "classes = []\n",
        "widths = []\n",
        "heights = []\n",
        "file_names = []\n",
        "\n",
        "for i in train_file_names:\n",
        "    with open(i,'r') as f:\n",
        "        data = json.load(f)\n",
        "        convert_to_txt(i,\n",
        "                    data['shapes'][0]['label'],\n",
        "                    data['shapes'][0]['points'][0],\n",
        "                    data['shapes'][0]['points'][1],\n",
        "                    data['imageWidth'],\n",
        "                    data['imageHeight'])\n",
        "\n",
        "num = len(file_names)\n",
        "#name = '/content/Dataset/labels/train/'\n",
        "print(num)\n",
        "for i in range(num):\n",
        "    fn = file_names[i]\n",
        "    with open(fn,'w+') as f:\n",
        "        x = x_centers[i]\n",
        "        y = y_centers[i]\n",
        "        w = widths[i]\n",
        "        h = heights[i]\n",
        "        cl = classes[i]\n",
        "\n",
        "        f.write(str(cl)+' '+str(x)+' '+str(y)+' '+str(w)+' '+str(h))"
      ],
      "metadata": {
        "id": "AoiMUMKpg5Lc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b9aa734-0a70-43df-d2e1-5356374b9554"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4174\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_file = glob.glob('/content/Dataset/labels/train/*.txt')\n",
        "text_file[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zAOwQPV_b6p",
        "outputId": "ddbdcef0-c82f-4e83-aed0-25abafc472a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/Dataset/labels/train/500_1113_9.txt',\n",
              " '/content/Dataset/labels/train/50000_F_STUFF_0_16.txt',\n",
              " '/content/Dataset/labels/train/50000_F_DESK_0_118.txt',\n",
              " '/content/Dataset/labels/train/500_792_1.txt',\n",
              " '/content/Dataset/labels/train/10_6914_1.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "########################\n",
        "# 이 셀부터 코드 작성하세요\n",
        "# Json 파일에서 필요한 정보만 골라 txt로 바꾸는 작업임을 기억하세요!\n",
        "########################\n",
        "x_centers = []\n",
        "y_centers = []\n",
        "classes = []\n",
        "widths = []\n",
        "heights = []\n",
        "file_names = []\n",
        "\n",
        "for i in val_file_names:\n",
        "    with open(i,'r') as f:\n",
        "        data = json.load(f)\n",
        "        convert_to_txt(i,\n",
        "                    data['shapes'][0]['label'],\n",
        "                    data['shapes'][0]['points'][0],\n",
        "                    data['shapes'][0]['points'][1],\n",
        "                    data['imageWidth'],\n",
        "                    data['imageHeight'])\n",
        "\n",
        "num = len(file_names)\n",
        "print(num)\n",
        "#name = '/content/Dataset/labels/val/'\n",
        "\n",
        "for i in range(num):\n",
        "    fn = file_names[i]\n",
        "    with open(fn,'w+') as f:\n",
        "        x = x_centers[i]\n",
        "        y = y_centers[i]\n",
        "        w = widths[i]\n",
        "        h = heights[i]\n",
        "        cl = classes[i]\n",
        "\n",
        "        f.write(str(cl)+' '+str(x)+' '+str(y)+' '+str(w)+' '+str(h))"
      ],
      "metadata": {
        "id": "wFfvRVamg9cM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1926c86c-371c-447b-d7d1-d7c4b8197c87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_file = glob.glob('/content/Dataset/labels/val/*.txt')\n",
        "text_file[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sC7WkNPYsuk",
        "outputId": "12237ed7-1343-4958-84ac-85a03a88bf97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/Dataset/labels/val/500_556_1.txt',\n",
              " '/content/Dataset/labels/val/1000_B_DESK_0_69.txt',\n",
              " '/content/Dataset/labels/val/1000_F_STUFF_0_47.txt',\n",
              " '/content/Dataset/labels/val/10_1274_9.txt',\n",
              " '/content/Dataset/labels/val/50000_F_HAND_0_7.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOQeEhApesWR"
      },
      "source": [
        "### (3) 데이터셋 정보가 담긴 파일 생성\n",
        "---\n",
        "- **세부요구사항**\n",
        "    - 파일 안에 있어야 할 정보는 아래와 같습니다.\n",
        "        - 학습할 클래스 이름 정보\n",
        "        - 학습할 클래스 수 정보\n",
        "        - Training, Validation 데이터셋 위치 정보\n",
        "---\n",
        "- 가장 대중적으로 이용하는 라이브러리는 yaml 입니다.\n",
        "    - [yaml document](https://pyyaml.org/wiki/PyYAMLDocumentation)\n",
        "    - 해당 모듈 이외에 자신이 잘 알고 있는 방법을 사용해도 됩니다.\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "won_dict = {0:'10', 1:'50', 2:'100', 3:'500', 4:'1000', 5:'5000', 6:'10000',7:'50000'}\n",
        "\n",
        "yaml_data = {\n",
        "        \"path\":\"/content/Dataset\",\n",
        "        \"train\":\"images/train/\",\n",
        "        \"val\":\"images/val/\",\n",
        "        \"nc\":8,\n",
        "        \"names\":won_dict\n",
        "    }\n",
        "\n",
        "print(yaml.dump(yaml_data))"
      ],
      "metadata": {
        "id": "t1_uOeXcSvv3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ecaeac6-9792-4043-8dcd-7e53c8c40206"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "names:\n",
            "  0: '10'\n",
            "  1: '50'\n",
            "  2: '100'\n",
            "  3: '500'\n",
            "  4: '1000'\n",
            "  5: '5000'\n",
            "  6: '10000'\n",
            "  7: '50000'\n",
            "nc: 8\n",
            "path: /content/Dataset\n",
            "train: images/train/\n",
            "val: images/val/\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvMQcHirmSnD"
      },
      "outputs": [],
      "source": [
        "########################\n",
        "# 이 셀부터 코드 작성하세요\n",
        "########################\n",
        "with open('/content/Dataset/money.yaml', 'w') as f :\n",
        "    yaml.dump(yaml_data, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.모델링"
      ],
      "metadata": {
        "id": "3btFvySXi2dt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pQ2gRbTYgLL"
      },
      "source": [
        "### (1) 모델 라이브러리 설치\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "!pip install -r yolov5/requirements.txt  # install"
      ],
      "metadata": {
        "id": "Biyr9AHkMyNf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25dfe203-6bf6-4398-8cde-1cfa80181b1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'yolov5' already exists and is not an empty directory.\n",
            "Requirement already satisfied: gitpython>=3.1.30 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 5)) (3.1.37)\n",
            "Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 6)) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 7)) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 8)) (4.8.0.76)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 9)) (9.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 11)) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 12)) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 13)) (1.11.2)\n",
            "Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 14)) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 15)) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 16)) (0.15.2+cu118)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 17)) (4.66.1)\n",
            "Requirement already satisfied: ultralytics>=8.0.147 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 18)) (8.0.186)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 27)) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 28)) (0.12.2)\n",
            "Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.10/dist-packages (from -r yolov5/requirements.txt (line 42)) (67.7.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython>=3.1.30->-r yolov5/requirements.txt (line 5)) (4.0.10)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (23.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 12)) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 12)) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 12)) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 12)) (2023.7.22)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (16.0.6)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.0.147->-r yolov5/requirements.txt (line 18)) (9.0.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r yolov5/requirements.txt (line 27)) (2023.3.post1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r yolov5/requirements.txt (line 5)) (5.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->-r yolov5/requirements.txt (line 15)) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (2) 가중치 파일 다운로드\n",
        "---\n",
        "- **세부요구사항**\n",
        "    - 모델 개발자가 제공하는 사전 학습 가중치 파일을 다운로드 하세요.\n",
        "        - 해당 과정이 불필요하다면 넘어가셔도 됩니다!\n",
        "---"
      ],
      "metadata": {
        "id": "_mHMAspjR6Xp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "########################\n",
        "# 이 셀부터 코드 작성하세요\n",
        "########################\n",
        "!python /content/yolov5/detect.py --weights yolov5n.pt"
      ],
      "metadata": {
        "id": "sSVIqkMLDIOd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a25f476-adca-498a-8a06-2fb0c3fb1d38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['yolov5n.pt'], source=yolov5/data/images, data=yolov5/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov5/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 🚀 v7.0-224-g6262c7f Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients\n",
            "image 1/2 /content/yolov5/data/images/bus.jpg: 640x480 4 persons, 1 bus, 47.8ms\n",
            "image 2/2 /content/yolov5/data/images/zidane.jpg: 384x640 2 persons, 1 tie, 49.2ms\n",
            "Speed: 0.6ms pre-process, 48.5ms inference, 1.3ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1myolov5/runs/detect/exp6\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8-5lC4mfbwT"
      },
      "source": [
        "### (3) 학습 : train.py\n",
        "---\n",
        "- **세부요구사항**\n",
        "    - UltraLytics YOLO v5에는 아래의 데이터가 필요합니다.\n",
        "        - 데이터셋 정보가 담긴 yaml 파일\n",
        "        - 사용하려는 모델 구조에 대한 yaml 파일\n",
        "        - 사용하려는 모델의 가중치 파일\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AYFDMaVfmTK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71cdae69-8b0c-4fb1-ebd8-0e2b6f0322d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=/content/yolov5/yolov5n.pt, cfg=/content/yolov5/models/yolov5n.yaml, data=/content/Dataset/money.yaml, hyp=yolov5/data/hyps/hyp.scratch-low.yaml, epochs=20, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5/runs/train, name=yolov5_coco, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-224-g6262c7f Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5/runs/train', view at http://localhost:6006/\n",
            "Overriding model.yaml nc=80 with nc=8\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      1760  models.common.Conv                      [3, 16, 6, 2, 2]              \n",
            "  1                -1  1      4672  models.common.Conv                      [16, 32, 3, 2]                \n",
            "  2                -1  1      4800  models.common.C3                        [32, 32, 1]                   \n",
            "  3                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  4                -1  2     29184  models.common.C3                        [64, 64, 2]                   \n",
            "  5                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  6                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  7                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  8                -1  1    296448  models.common.C3                        [256, 256, 1]                 \n",
            "  9                -1  1    164608  models.common.SPPF                      [256, 256, 5]                 \n",
            " 10                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 14                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     22912  models.common.C3                        [128, 64, 1, False]           \n",
            " 18                -1  1     36992  models.common.Conv                      [64, 64, 3, 2]                \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1     74496  models.common.C3                        [128, 128, 1, False]          \n",
            " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 24      [17, 20, 23]  1     17589  models.yolo.Detect                      [8, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [64, 128, 256]]\n",
            "YOLOv5n summary: 214 layers, 1774741 parameters, 1774741 gradients, 4.3 GFLOPs\n",
            "\n",
            "Transferred 342/349 items from /content/yolov5/yolov5n.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Dataset/labels/train.cache... 3343 images, 831 backgrounds, 0 corrupt: 100% 4174/4174 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Dataset/labels/val... 213 images, 831 backgrounds, 0 corrupt: 100% 1044/1044 [00:00<00:00, 5003.48it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Dataset/labels/val.cache\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.02 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to yolov5/runs/train/yolov5_coco2/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1myolov5/runs/train/yolov5_coco2\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/19      1.97G    0.06436    0.02191    0.05532         24        640: 100% 261/261 [00:46<00:00,  5.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:06<00:00,  4.72it/s]\n",
            "                   all       1044        213     0.0508      0.495     0.0768     0.0357\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/19      2.14G    0.03852    0.01276    0.04295         20        640: 100% 261/261 [00:42<00:00,  6.07it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:05<00:00,  6.21it/s]\n",
            "                   all       1044        213     0.0916      0.617      0.143     0.0931\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/19      2.14G    0.03635    0.01056    0.03059         24        640: 100% 261/261 [00:43<00:00,  6.03it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:05<00:00,  6.07it/s]\n",
            "                   all       1044        213      0.117      0.814      0.162      0.107\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/19      2.14G    0.03172   0.009458    0.02555         22        640: 100% 261/261 [00:42<00:00,  6.08it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:05<00:00,  6.21it/s]\n",
            "                   all       1044        213      0.108      0.717      0.135     0.0997\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/19      2.14G    0.02742   0.008851    0.02276         18        640: 100% 261/261 [00:43<00:00,  6.06it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:05<00:00,  6.38it/s]\n",
            "                   all       1044        213      0.124      0.931      0.187      0.156\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/19      2.14G    0.02406   0.008602    0.02191         22        640: 100% 261/261 [00:42<00:00,  6.13it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:05<00:00,  5.74it/s]\n",
            "                   all       1044        213      0.122      0.745      0.181      0.144\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/19      2.14G    0.02189   0.008063    0.02055         30        640: 100% 261/261 [00:42<00:00,  6.11it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:05<00:00,  6.13it/s]\n",
            "                   all       1044        213      0.144      0.897      0.185      0.162\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/19      2.14G    0.02088    0.00788    0.01929         24        640: 100% 261/261 [00:43<00:00,  6.00it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:05<00:00,  5.83it/s]\n",
            "                   all       1044        213       0.12      0.789      0.143       0.12\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/19      2.14G    0.01934   0.007635    0.01877         23        640: 100% 261/261 [00:42<00:00,  6.11it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:05<00:00,  5.86it/s]\n",
            "                   all       1044        213      0.163      0.746      0.206      0.185\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/19      2.14G    0.01773    0.00736    0.01675         27        640: 100% 261/261 [00:42<00:00,  6.15it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:05<00:00,  6.23it/s]\n",
            "                   all       1044        213      0.213      0.757      0.246       0.22\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/19      2.14G    0.01665   0.007231    0.01552         23        640: 100% 261/261 [00:42<00:00,  6.13it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:05<00:00,  5.57it/s]\n",
            "                   all       1044        213       0.19      0.811      0.207      0.185\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/19      2.14G    0.01579   0.007162     0.0147         29        640: 100% 261/261 [00:43<00:00,  6.07it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 33/33 [00:05<00:00,  6.49it/s]\n",
            "                   all       1044        213      0.165      0.843       0.22        0.2\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/19      2.14G    0.01512   0.007088    0.01305         23        640:  88% 229/261 [00:37<00:06,  5.18it/s]"
          ]
        }
      ],
      "source": [
        "########################\n",
        "# 이 셀부터 코드 작성하세요\n",
        "########################\n",
        "!python /content/yolov5/train.py --epochs 20 --data /content/Dataset/money.yaml --cfg /content/yolov5/models/yolov5n.yaml --weights /content/yolov5/yolov5n.pt --name yolov5_coco"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2YESAa5fc4M"
      },
      "source": [
        "## 4.탐지 : detect.py\n",
        "---\n",
        "- **세부요구사항**\n",
        "    - 학습 과정에서 생성된 가중치 파일을 이용하세요.\n",
        "    - IoU threshold를 0.25 이하로 설정하세요.\n",
        "    - confidence threshold를 0.75 이상으로 설정하세요.\n",
        "---\n",
        "- 여러분이 **직접 촬영한 화폐 사진과 동영상**을 탐지 과정에 이용하여 결과를 확인하세요.\n",
        "    - 조건\n",
        "        1. 화폐의 수를 늘려가며 촬영 해보세요.\n",
        "            - ex) 50원 하나, 50원 둘, 50원 셋, ...\n",
        "        2. 화폐의 종류를 늘려가며 촬영 해보세요.\n",
        "            - ex) 50원 하나와 100원 하나, 50원 하나와 100원 하나와 1000원 하나, ...\n",
        "        3. 사진은 최소 30장 이상, 동영상은 최소 하나 이상 촬영하여 사용 해보세요.\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "########################\n",
        "# 이 셀부터 코드 작성하세요\n",
        "########################\n",
        "!python /content/yolov5/detect.py --weights /content/yolov5/runs/train/yolov5_coco/weights/best.pt --source /content/drive/MyDrive/project_0921/datas/"
      ],
      "metadata": {
        "id": "9rK0ClfTcjEZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba2fd1f9-4ef5-45a6-bbec-e26a533979d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/yolov5/runs/train/yolov5_coco/weights/best.pt'], source=/content/drive/MyDrive/project_0921/datas/, data=yolov5/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov5/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 🚀 v7.0-224-g6262c7f Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5n summary: 157 layers, 1769989 parameters, 0 gradients, 4.2 GFLOPs\n",
            "image 1/12 /content/drive/MyDrive/project_0921/datas/Fifty_01.jpg: 640x640 1 50, 6.1ms\n",
            "image 2/12 /content/drive/MyDrive/project_0921/datas/Fifty_thousand_01.jpg: 640x384 1 50000, 48.1ms\n",
            "image 3/12 /content/drive/MyDrive/project_0921/datas/Fifty_thousand_02.jpg: 384x640 1 50000, 47.8ms\n",
            "image 4/12 /content/drive/MyDrive/project_0921/datas/Five_hundred_01.jpg: 640x384 1 500, 6.3ms\n",
            "image 5/12 /content/drive/MyDrive/project_0921/datas/Five_thousand_01.jpg: 640x480 1 5000, 47.3ms\n",
            "image 6/12 /content/drive/MyDrive/project_0921/datas/Five_thousand_02.jpg: 640x480 1 5000, 5.8ms\n",
            "image 7/12 /content/drive/MyDrive/project_0921/datas/One_hundred_01.jpg: 640x384 1 100, 6.0ms\n",
            "image 8/12 /content/drive/MyDrive/project_0921/datas/One_thousand_01.jpg: 640x480 1 1000, 6.9ms\n",
            "image 9/12 /content/drive/MyDrive/project_0921/datas/One_thousand_02.jpg: 480x640 1 1000, 46.9ms\n",
            "image 10/12 /content/drive/MyDrive/project_0921/datas/Ten_01.jpg: 640x320 1 10, 44.8ms\n",
            "image 11/12 /content/drive/MyDrive/project_0921/datas/Ten_thousand_01.jpg: 640x320 1 10000, 7.3ms\n",
            "image 12/12 /content/drive/MyDrive/project_0921/datas/Ten_thousand_02.jpg: 640x384 1 10000, 6.0ms\n",
            "Speed: 0.6ms pre-process, 23.3ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1myolov5/runs/detect/exp2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/yolov5/detect.py --weights /content/yolov5/runs/train/yolov5_coco/weights/best.pt --iou-thres=0.25 --conf 0.75 --source /content/drive/MyDrive/project_0921/datas/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xn5YTNPVVRtu",
        "outputId": "d3fd55b8-485f-4e37-8955-539051a63c01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/yolov5/runs/train/yolov5_coco/weights/best.pt'], source=/content/drive/MyDrive/project_0921/datas/, data=yolov5/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.75, iou_thres=0.25, max_det=1000, device=, view_img=False, save_txt=False, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov5/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 🚀 v7.0-224-g6262c7f Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5n summary: 157 layers, 1769989 parameters, 0 gradients, 4.2 GFLOPs\n",
            "image 1/12 /content/drive/MyDrive/project_0921/datas/Fifty_01.jpg: 640x640 1 50, 5.5ms\n",
            "image 2/12 /content/drive/MyDrive/project_0921/datas/Fifty_thousand_01.jpg: 640x384 1 50000, 45.6ms\n",
            "image 3/12 /content/drive/MyDrive/project_0921/datas/Fifty_thousand_02.jpg: 384x640 1 50000, 45.1ms\n",
            "image 4/12 /content/drive/MyDrive/project_0921/datas/Five_hundred_01.jpg: 640x384 1 500, 5.9ms\n",
            "image 5/12 /content/drive/MyDrive/project_0921/datas/Five_thousand_01.jpg: 640x480 1 5000, 45.2ms\n",
            "image 6/12 /content/drive/MyDrive/project_0921/datas/Five_thousand_02.jpg: 640x480 1 5000, 5.8ms\n",
            "image 7/12 /content/drive/MyDrive/project_0921/datas/One_hundred_01.jpg: 640x384 (no detections), 6.3ms\n",
            "image 8/12 /content/drive/MyDrive/project_0921/datas/One_thousand_01.jpg: 640x480 1 1000, 6.2ms\n",
            "image 9/12 /content/drive/MyDrive/project_0921/datas/One_thousand_02.jpg: 480x640 1 1000, 46.8ms\n",
            "image 10/12 /content/drive/MyDrive/project_0921/datas/Ten_01.jpg: 640x320 1 10, 45.1ms\n",
            "image 11/12 /content/drive/MyDrive/project_0921/datas/Ten_thousand_01.jpg: 640x320 1 10000, 7.9ms\n",
            "image 12/12 /content/drive/MyDrive/project_0921/datas/Ten_thousand_02.jpg: 640x384 1 10000, 6.0ms\n",
            "Speed: 0.5ms pre-process, 22.6ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1myolov5/runs/detect/exp4\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/yolov5/detect.py --weights /content/yolov5/runs/train/yolov5_coco/weights/best.pt --source 'https://youtu.be/NGen9lbU0NU'"
      ],
      "metadata": {
        "id": "2tXyqasEVSEH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d7c9c0f-a518-410b-f66e-4fd5b4bc38ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
            "  File \"/content/yolov5/utils/general.py\", line 1115, in <module>\n",
            "    if Path(inspect.stack()[0].filename).parent.parent.as_posix() in inspect.stack()[-1].filename:\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1673, in stack\n",
            "    return getouterframes(sys._getframe(1), context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1650, in getouterframes\n",
            "    frameinfo = (frame,) + getframeinfo(frame, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1624, in getframeinfo\n",
            "    lines, lnum = findsource(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 952, in findsource\n",
            "    module = getmodule(object, file)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 869, in getmodule\n",
            "    if ismodule(module) and hasattr(module, '__file__'):\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov5/detect.py\", line 48, in <module>\n",
            "    from models.common import DetectMultiBackend\n",
            "  File \"/content/yolov5/models/common.py\", line 41, in <module>\n",
            "    from utils.dataloaders import exif_transpose, letterbox\n",
            "  File \"/content/yolov5/utils/dataloaders.py\", line 31, in <module>\n",
            "    from utils.augmentations import (Albumentations, augment_hsv, classify_albumentations, classify_transforms, copy_paste,\n",
            "  File \"/content/yolov5/utils/augmentations.py\", line 15, in <module>\n",
            "    from utils.general import LOGGER, check_version, colorstr, resample_segments, segment2box, xywhn2xyxy\n",
            "  File \"<frozen importlib._bootstrap>\", line 1024, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 174, in __exit__\n",
            "  File \"<frozen importlib._bootstrap>\", line 126, in release\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}