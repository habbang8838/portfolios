{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77055a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3fd087",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483e047e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow keras opencv-python numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dfc1b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7f27309",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv('Labels/TrainLabels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f17d7dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = pd.read_csv('Labels/TestLabels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00e7ed1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    882\n",
       "3    814\n",
       "1     84\n",
       "0      4\n",
       "Name: Engagement, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels['Engagement'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6beb3a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f21182e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8264120240.avi', '5100351022.avi', '9877360133.avi', '5100342022.avi']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(list(test_labels[test_labels['Engagement'] == 0]['ClipID']), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f3016ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClipID</th>\n",
       "      <th>Boredom</th>\n",
       "      <th>Engagement</th>\n",
       "      <th>Confusion</th>\n",
       "      <th>Frustration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1100011002.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1100011003.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1100011004.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1100011005.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1100011006.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5352</th>\n",
       "      <td>4599990246.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5353</th>\n",
       "      <td>4599990247.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5354</th>\n",
       "      <td>4599990248.avi</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5355</th>\n",
       "      <td>4599990249.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5356</th>\n",
       "      <td>459999025.avi</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5357 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ClipID  Boredom  Engagement  Confusion  Frustration \n",
       "0     1100011002.avi        0           2          0             0\n",
       "1     1100011003.avi        0           2          0             0\n",
       "2     1100011004.avi        0           3          0             0\n",
       "3     1100011005.avi        0           3          0             0\n",
       "4     1100011006.avi        0           3          0             0\n",
       "...              ...      ...         ...        ...           ...\n",
       "5352  4599990246.avi        0           3          0             0\n",
       "5353  4599990247.avi        0           3          0             0\n",
       "5354  4599990248.avi        1           2          1             1\n",
       "5355  4599990249.avi        0           3          0             0\n",
       "5356   459999025.avi        1           3          0             0\n",
       "\n",
       "[5357 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f9faed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['248510233.mp4',\n",
       " '1100142056.avi',\n",
       " '4140810154.avi',\n",
       " '2100572050.avi',\n",
       " '29042801630.mp4',\n",
       " '24851027.mp4',\n",
       " '303830184.mp4',\n",
       " '1813740127.avi',\n",
       " '3344630110.avi',\n",
       " '3100791061.avi',\n",
       " '4000181066.avi',\n",
       " '3100741063.avi',\n",
       " '1100011064.avi',\n",
       " '2408460151.avi',\n",
       " '3100791045.avi',\n",
       " '33446301107.avi',\n",
       " '1110032032.avi',\n",
       " '2408460276.avi',\n",
       " '3344630260.avi',\n",
       " '2100592044.avi',\n",
       " '248510273.mp4',\n",
       " '1100062009.avi',\n",
       " '3344630271.avi',\n",
       " '1813740238.avi',\n",
       " '303830236.mp4',\n",
       " '3100742011.avi',\n",
       " '3100752052.avi',\n",
       " '1100072012.avi',\n",
       " '3100721016.avi',\n",
       " '4599990137.avi']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(list(train_labels[train_labels['Engagement'] == 3]['ClipID']), 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60763ab0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1100121049.avi',\n",
       " '3100771075.avi',\n",
       " '3422270142.avi',\n",
       " '2100552003.avi',\n",
       " '2000541035.avi',\n",
       " '3100631023.avi',\n",
       " '2100592070.avi',\n",
       " '2100602001.avi',\n",
       " '3503610133.avi',\n",
       " '1100121041.avi',\n",
       " '4110311068.avi',\n",
       " '1100042059.avi',\n",
       " '4110212024.avi',\n",
       " '3344630116.avi',\n",
       " '2100521031.avi',\n",
       " '3100812016.avi',\n",
       " '3100772025.avi',\n",
       " '2100602024.avi',\n",
       " '2100602004.avi',\n",
       " '3100771055.avi',\n",
       " '3100622026.avi',\n",
       " '1100071026.avi',\n",
       " '1100121033.avi',\n",
       " '2100572030.avi',\n",
       " '3100762016.avi',\n",
       " '2408460211.avi',\n",
       " '3344630171.avi',\n",
       " '4018350279.mp4',\n",
       " '3100751064.avi',\n",
       " '3422270251.avi',\n",
       " '1100052070.avi',\n",
       " '33702101600.mp4',\n",
       " '2100602003.avi',\n",
       " '1100161029.avi']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(list(train_labels[train_labels['Engagement'] == 2]['ClipID']), 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2d44530",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = pd.read_csv('Labels/ValidationLabels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5f96663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    813\n",
       "3    450\n",
       "1    143\n",
       "0     23\n",
       "Name: Engagement, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_labels['Engagement'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49d96a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5000431050.avi',\n",
       " '5674960216.avi',\n",
       " '4100282024.avi',\n",
       " '4100321026.avi',\n",
       " '4000221017.avi',\n",
       " '4100201004.avi',\n",
       " '5674960276.avi',\n",
       " '567496019.avi',\n",
       " '4000221016.avi',\n",
       " '556463027.avi']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10ê°œì”© ì¶”ì¶œ\n",
    "random.sample(list(val_labels[val_labels['Engagement'] == 3]['ClipID']), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ea1b21",
   "metadata": {},
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture('DataSet/Train/110005/1100051002/1100051002.avi')\n",
    "#num = 0\n",
    "while (cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        cv2.imshow(\"frame\", frame)\n",
    "        #filepath = \"snapshot/snapshot_\" + str(num) + \".jpg\"\n",
    "        #cv2.imwrite(filepath, frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    #num += 1\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f49004a",
   "metadata": {},
   "source": [
    "import cv2\n",
    "import sys\n",
    "\n",
    "set_dir_images = []\n",
    "humans = os.listdir('DataSet/Train/')\n",
    "for human in humans:\n",
    "    human_dir = \"DataSet/Train/\" + human + \"/\"\n",
    "    videos = os.listdir(human_dir)\n",
    "    for video in videos:\n",
    "        video_dir = human_dir + video + \"/\"\n",
    "        con = os.listdir(video_dir)[0]\n",
    "        print(con)\n",
    "        cap = cv2.VideoCapture(con)\n",
    "        num = 0\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if ret:\n",
    "                cv2.imshow(\"frame\", frame)\n",
    "                filepath = \"snapshot/snapshot_\" + str(num) + \".jpg\"\n",
    "                cv2.imwrite(filepath, frame)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            num += 1\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bdb2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6663997",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import tensorflow_datasets as tfds\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "batch_size = 32\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "class DataPreprocessing:\n",
    "    def __init__(self,\n",
    "                 IMG_HEIGHT=224,\n",
    "                 IMG_WIDTH=224,\n",
    "                 dataset_dir='DataSet/',\n",
    "                 test_dir='Test/',\n",
    "                 train_dir='Train/',\n",
    "                 val_dir='Validation/',\n",
    "                 labels_dir='Labels/',\n",
    "                 test_label='TestLabels.csv',\n",
    "                 train_label='TrainLabels.csv',\n",
    "                 val_label='ValidationLabels.csv',\n",
    "                 data_augmentation_flag=False,\n",
    "                 max_frames=1\n",
    "                 ):\n",
    "        self.IMG_HEIGHT = IMG_HEIGHT\n",
    "        self.IMG_WIDTH = IMG_WIDTH\n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.train_dir = self.dataset_dir+train_dir\n",
    "        self.test_dir = self.dataset_dir+test_dir\n",
    "        self.val_dir = self.dataset_dir+val_dir\n",
    "        self.labels_dir = labels_dir\n",
    "        self.train_label_dir = self.labels_dir + train_label\n",
    "        self.test_label_dir = self.labels_dir + test_label\n",
    "        self.val_label_dir = self.labels_dir + val_label\n",
    "        self.data_augmentation_flag = data_augmentation_flag\n",
    "        self.max_frames = max_frames\n",
    "        self.face_cascade = cv2.CascadeClassifier('dataset/haarcascade_frontalface_default.xml')\n",
    "\n",
    "    def get_images_from_set_dir(self, setdir):\n",
    "        '''\n",
    "        Method to find all images in the tree folder\n",
    "        '''\n",
    "        set_dir_images = []\n",
    "        humans = os.listdir(setdir)\n",
    "        for human in humans:\n",
    "            human_dir = setdir + human + \"/\"\n",
    "            videos = os.listdir(human_dir)\n",
    "            for video in videos:\n",
    "                video_dir = human_dir + video + \"/\"    \n",
    "                pictures = os.listdir(video_dir)\n",
    "                pictures = random.sample(pictures, self.max_frames)\n",
    "                for picture in pictures:\n",
    "                    picture_dir = video_dir + picture\n",
    "                    if picture.endswith(\".jpg\"):\n",
    "                        set_dir_images.append(picture_dir)\n",
    "                        \n",
    "        return set_dir_images\n",
    "\n",
    "    def get_labels_dataframe(self):\n",
    "        '''\n",
    "        Method to read pandas dataframe\n",
    "        '''\n",
    "        train_df = pd.read_csv(self.train_label_dir, sep=\",\")\n",
    "        test_df = pd.read_csv(self.test_label_dir, sep=\",\")\n",
    "        val_df = pd.read_csv(self.val_label_dir, sep=\",\")\n",
    "        return train_df, test_df, val_df\n",
    "\n",
    "    def resize(self, image):\n",
    "        return cv2.resize(image, (self.IMG_HEIGHT, self.IMG_WIDTH), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    def face_cropping(self, image):\n",
    "        # Crop and resize\n",
    "        faces = self.face_cascade.detectMultiScale(image, 1.3, 5)\n",
    "        try:\n",
    "            if faces != 0:\n",
    "                x, y, w, h = faces[0]\n",
    "                image = image[y:y+h, x:x+w]\n",
    "        except:\n",
    "            pass\n",
    "        return self.resize(image)\n",
    "\n",
    "    def random_crop(self, image, crop_height, crop_width):\n",
    "        max_x = image.shape[1] - crop_width\n",
    "        max_y = image.shape[0] - crop_height\n",
    "\n",
    "        x = np.random.randint(0, max_x)\n",
    "        y = np.random.randint(0, max_y)\n",
    "\n",
    "        crop = image[y: y + crop_height, x: x + crop_width]\n",
    "\n",
    "        return self.face_cropping(crop)\n",
    "\n",
    "\n",
    "    def augment_image(self, image):\n",
    "        '''\n",
    "        Applies some augmentation techniques\n",
    "        '''\n",
    "        # Mirror flip\n",
    "        flipped = tf.image.flip_left_right(image).numpy()\n",
    "        # Transpose flip\n",
    "        transposed = tf.image.transpose(image).numpy()\n",
    "        # Saturation\n",
    "        satured = tf.image.adjust_saturation(image, 3).numpy()\n",
    "        # Brightness\n",
    "        brightness = tf.image.adjust_brightness(image, 0.4).numpy()\n",
    "        # Contrast\n",
    "        contrast = tf.image.random_contrast(image, lower=0.0, upper=1.0).numpy()\n",
    "        # Resize at the end\n",
    "        images = [self.resize(image) for image in [flipped, transposed, satured, brightness, contrast]]\n",
    "        return images\n",
    "\n",
    "\n",
    "    def get_label_picture(self, image_path, label_df):\n",
    "        error_ = False\n",
    "        video = image_path.split(\"/\")[-2]\n",
    "        label_series = label_df.loc[((label_df['ClipID'] == video+'.avi') | (label_df['ClipID'] == video+'.mp4'))]\n",
    "        try:\n",
    "            index = label_series.index.values[0]\n",
    "            label = np.array([label_series['Boredom'].get(index),\n",
    "                              label_series['Engagement'].get(index),\n",
    "                              label_series['Confusion'].get(index),\n",
    "                              label_series['Frustration '].get(index)])\n",
    "            label_one_hot = (label >= 1).astype(np.uint8)\n",
    "        except:\n",
    "            print('Error in label picture')\n",
    "            print(image_path)\n",
    "            label_one_hot = ''\n",
    "            error_ = True\n",
    "        return label_one_hot, error_\n",
    "\n",
    "    def _int64_feature(self, value):\n",
    "        return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "    def _bytes_feature(self, value):\n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "    def writeTfRecord(self, output_dir, data_augmentation=False):\n",
    "        '''\n",
    "        Method to write tfrecord\n",
    "        '''\n",
    "        # open the TFRecords file\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "        # Read dataframes\n",
    "        train_df, test_df, val_df = self.get_labels_dataframe()\n",
    "\n",
    "        # Objects to iterate\n",
    "        objs = [('train', self.train_dir, train_df),\n",
    "                ('test', self.test_dir, test_df),\n",
    "                ('val', self.val_dir, val_df)]\n",
    "\n",
    "        for name, dataset, label_df in tqdm(objs):\n",
    "            # Open Writer\n",
    "            writer = tf.io.TFRecordWriter(output_dir+name+'.tfrecords')\n",
    "            # Get all the images of a set\n",
    "            images_path = self.get_images_from_set_dir(dataset)\n",
    "            for image_path in tqdm(images_path, total=len(images_path)):\n",
    "                # Read the image from path\n",
    "                img = cv2.imread(image_path)[..., ::-1]\n",
    "                img = self.face_cropping(img)\n",
    "                # Read the label\n",
    "                label, error_ = self.get_label_picture(image_path, label_df)\n",
    "                if error_:\n",
    "                    continue\n",
    "                # Create a feature\n",
    "                if data_augmentation:\n",
    "                    images = self.augment_image(img)\n",
    "                else:\n",
    "                    images = img\n",
    "                for image in images:\n",
    "                    feature = {'label': self._bytes_feature(tf.compat.as_bytes(label.tostring())),\n",
    "                               'image': self._bytes_feature(tf.compat.as_bytes(image.tostring()))}\n",
    "                    # Create an example protocol buffer\n",
    "                    example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "                    # Serialize to string and write on the file\n",
    "                    writer.write(example.SerializeToString())\n",
    "            writer.close()\n",
    "\n",
    "    def decode(self, serialized_example):\n",
    "        \"\"\"\n",
    "        Parses an image and label from the given `serialized_example`.\n",
    "        It is used as a map function for `dataset.map`\n",
    "        \"\"\"\n",
    "        IMAGE_SHAPE = (self.IMG_HEIGHT, self.IMG_WIDTH, 3)\n",
    "\n",
    "        # 1. define a parser\n",
    "        features = tf.io.parse_single_example(\n",
    "            serialized_example,\n",
    "            # Defaults are not specified since both keys are required.\n",
    "            features={\n",
    "                'image': tf.io.FixedLenFeature([], tf.string),\n",
    "                'label': tf.io.FixedLenFeature([], tf.string),\n",
    "            })\n",
    "\n",
    "        # 2. Convert the data\n",
    "        image = tf.io.decode_raw(features['image'], tf.uint8)\n",
    "        label = tf.io.decode_raw(features['label'], tf.uint8)\n",
    "\n",
    "        # Cast\n",
    "        label = tf.cast(label, tf.float32)\n",
    "\n",
    "        # 3. reshape\n",
    "        image = tf.convert_to_tensor(tf.reshape(image, IMAGE_SHAPE))\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    preprocessing_class = DataPreprocessing()\n",
    "    # Write tf recordfloat32\n",
    "    preprocessing_class.writeTfRecord('tfrecords/', data_augmentation=True)\n",
    "\n",
    "    # Read TfRecord\n",
    "    tfrecord_path = 'tfrecords/train.tfrecords'\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
    "\n",
    "    # Parse the record into tensors with map.\n",
    "    # map takes a Python function and applies it to every sample.\n",
    "    dataset = dataset.map(preprocessing_class.decode)\n",
    "\n",
    "    # Divide in batch\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    # Create an iterator\n",
    "    iterator = iter(dataset)\n",
    "\n",
    "    # Element of iterator\n",
    "    #a = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11086459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def network():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(kl.InputLayer(input_shape=(224, 224, 3)))\n",
    "    # First conv block\n",
    "    model.add(kl.Conv2D(filters=96, kernel_size=7, padding='same', strides=2))\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "    model.add(kl.MaxPooling2D(pool_size=(3, 3)))\n",
    "    # Second conv block\n",
    "    model.add(kl.Conv2D(filters=256, kernel_size=5, padding='same', strides=1))\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "    model.add(kl.MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Third-Fourth-Fifth conv block\n",
    "    for i in range(3):\n",
    "        model.add(kl.Conv2D(filters=512, kernel_size=3, padding='same', strides=1))\n",
    "        model.add(tf.keras.layers.ReLU())\n",
    "    model.add(kl.MaxPooling2D(pool_size=(3, 3)))\n",
    "    # Flatten\n",
    "    model.add(kl.Flatten())\n",
    "    # First FC\n",
    "    model.add(kl.Dense(4048))\n",
    "    # Second Fc\n",
    "    model.add(kl.Dense(4048))\n",
    "    # Third FC\n",
    "    model.add(kl.Dense(4))\n",
    "    # Softmax at the end\n",
    "    model.add(kl.Softmax())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cbd4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as kl\n",
    "import tensorflow.keras.losses\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "#from daisee_data_preprocessing import DataPreprocessing\n",
    "import datetime\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "LR = 0.005\n",
    "EPOCHS = 100\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "checkpoint_dir = 'checkpoints/'\n",
    "log_dir = 'logs/'\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "### This part works for setting up space in gpu\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only allocate 1GB * 1 of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024 * 2)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "preprocessing_class = DataPreprocessing()\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "# Open train set\n",
    "tfrecord_path = 'tfrecords/train.tfrecords'\n",
    "train_set = tf.data.TFRecordDataset(tfrecord_path)\n",
    "# Parse the record into tensors with map.\n",
    "train_set = train_set.map(preprocessing_class.decode)\n",
    "train_set = train_set.shuffle(1)\n",
    "train_set = train_set.batch(BATCH_SIZE)\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "# Open test set\n",
    "tfrecord_path = 'tfrecords/test.tfrecords'\n",
    "test_set = tf.data.TFRecordDataset(tfrecord_path)\n",
    "# Parse the record into tensors with map.\n",
    "test_set = test_set.map(preprocessing_class.decode)\n",
    "test_set = test_set.shuffle(1)\n",
    "test_set = test_set.batch(BATCH_SIZE)\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "# Open val set\n",
    "tfrecord_path = 'tfrecords/val.tfrecords'\n",
    "val_set = tf.data.TFRecordDataset(tfrecord_path)\n",
    "# Parse the record into tensors with map.\n",
    "val_set = val_set.map(preprocessing_class.decode)\n",
    "val_set = val_set.shuffle(1)\n",
    "val_set = val_set.batch(BATCH_SIZE)\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "def create_log_dir(log_dir, checkpoint_dir):\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.mkdir(log_dir)\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.mkdir(checkpoint_dir)\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "def network():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(kl.InputLayer(input_shape=(224, 224, 3)))\n",
    "    # First conv block\n",
    "    model.add(kl.Conv2D(filters = 96, kernel_size=7, padding='same', strides=2))\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "    model.add(kl.MaxPooling2D(pool_size=(3, 3)))\n",
    "    # Second conv block\n",
    "    model.add(kl.Conv2D(filters = 256, kernel_size=5, padding='same', strides=1))\n",
    "    model.add(tf.keras.layers.ReLU())\n",
    "    model.add(kl.MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Third-Fourth-Fifth conv block\n",
    "    for i in range(3):\n",
    "        model.add(kl.Conv2D(filters = 512, kernel_size=3, padding='same', strides=1))\n",
    "        model.add(tf.keras.layers.ReLU())\n",
    "    model.add(kl.MaxPooling2D(pool_size=(3, 3)))\n",
    "    # Flatten\n",
    "    model.add(kl.Flatten())\n",
    "    # First FC \n",
    "    model.add(kl.Dense(4048))\n",
    "    # Second Fc\n",
    "    model.add(kl.Dense(4048))\n",
    "    # Third FC\n",
    "    model.add(kl.Dense(4))\n",
    "    # Softmax at the end\n",
    "    model.add(kl.Softmax())\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "model = network()\n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "'''\n",
    "https://keras.io/guides/writing_a_training_loop_from_scratch/\n",
    "Compile into a static graph any function that take tensors as input to apply global performance optimizations.\n",
    "'''\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(x)\n",
    "        loss_value = tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    # Track progress\n",
    "    train_loss_avg.update_state(loss_value)\n",
    "    train_accuracy.update_state(y, logits)\n",
    "    return loss_value\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def test_step(x, y, set_name):\n",
    "    logits = model(x)\n",
    "    if set_name == 'val':\n",
    "        val_accuracy.update_state(y, logits)\n",
    "    else:\n",
    "        test_accuracy.update_state(y, logits)\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LR)\n",
    "create_log_dir(log_dir, checkpoint_dir)\n",
    "train_summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "\n",
    "train_loss_avg = tf.keras.metrics.Mean()\n",
    "train_accuracy = tf.keras.metrics.MeanAbsoluteError()\n",
    "val_accuracy = tf.keras.metrics.MeanAbsoluteError()\n",
    "test_accuracy = tf.keras.metrics.MeanAbsoluteError()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Training loop\n",
    "    for x_batch_train, y_batch_train in tqdm(train_set, total=1517):\n",
    "        # Do step\n",
    "        loss_value = train_step(x_batch_train, y_batch_train)\n",
    "        \n",
    "    # Test on validation set\n",
    "    for x_batch_val, y_batch_val in val_set:\n",
    "        test_step(x_batch_val, y_batch_val, 'val')\n",
    "    \n",
    "    # Reset training metrics at the end of each epoch\n",
    "    train_acc = train_accuracy.result()\n",
    "    train_accuracy.reset_states()\n",
    "    val_acc = val_accuracy.result()\n",
    "    val_accuracy.reset_states()\n",
    "    \n",
    "    with train_summary_writer.as_default():\n",
    "        tf.summary.scalar('Train loss', train_loss_avg.result(), step=epoch)\n",
    "        tf.summary.scalar('Train MAE', train_acc, step=epoch)\n",
    "        tf.summary.scalar('Val MAE', val_acc, step=epoch)\n",
    "        \n",
    "    if epoch % 10 == 0:\n",
    "        tf.keras.models.save_model(model, '{}/Epoch_{}_model.hp5'.format(checkpoint_dir, str(epoch)), save_format=\"h5\")\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Test on validation set\n",
    "for x_batch_test, y_batch_test in test_set:\n",
    "    test_step(x_batch_test, y_batch_test, 'test')\n",
    "test_set_acc = test_accuracy.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3d57f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
